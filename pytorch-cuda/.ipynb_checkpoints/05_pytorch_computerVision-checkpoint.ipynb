{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2f043e",
   "metadata": {},
   "source": [
    "## computer vision libraries in pyTorch\n",
    "* **`[torchvision]`**:https://pytorch.org/vision/stable/index.html\n",
    "* **`[torchvision.datasets]`**\n",
    "* **`[torchvision.models]`**\n",
    "* **`[torchvision.transforms]`**\n",
    "* **`[torch.utils.data.Dataset]`**\n",
    "* **`[torch.utils.data.DataLoader]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3030f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import torchvision libraries\n",
    "import torchvision\n",
    "from torchvision import datasets   # to download the dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e63f65",
   "metadata": {},
   "source": [
    "## Getting a dataset\n",
    "* `documentation`: https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374264d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup training data\n",
    "\n",
    "train_data = datasets.FashionMNIST(root=\"data\", \n",
    "                                   train=True, \n",
    "                                   download=True,   # do we want the training dataset\n",
    "                                   transform = torchvision.transforms.ToTensor(), # do we want to transform the data\n",
    "                                   target_transform = None) # how do we want to transfrom the labels/targets\n",
    "\n",
    "test_data = datasets.FashionMNIST(root=\"data\",\n",
    "                                  train = False,\n",
    "                                  download=True,\n",
    "                                  transform = ToTensor(),\n",
    "                                  target_transform = None\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036ab49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b450ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d676be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## different output classes name\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fb6c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes with corresponding index value\n",
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e5f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n",
      "Image label: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# check the image shape and label\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab984aa5",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd08e4d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# matplotlib expect the image input in HxWxC but pyTorch reads the image as CxHxW\u001b[39;00m\n\u001b[0;32m      2\u001b[0m image, label \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\pyplot.py:2652\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2648\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2649\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2650\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2651\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2652\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2653\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2654\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2655\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2656\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2657\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2658\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2659\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2660\u001b[0m     sci(__ret)\n\u001b[0;32m   2661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5481\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5475\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[0;32m   5476\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5477\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5478\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5479\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5481\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5482\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5484\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\matplotlib\\image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (1, 28, 28) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib expect the image input in HxWxC but pyTorch reads the image as CxHxW\n",
    "image, label = train_data[1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79ec7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# right way to plot the image using matplotlib\n",
    "plt.imshow(torch.permute(image,(2,1,0)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00acbbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot more images at random order\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows, cols = 4,4\n",
    "for i in range(1, rows*cols+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.axis(False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468c50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed59540",
   "metadata": {},
   "source": [
    "## Prepare the Dataloader\n",
    "\n",
    "**Why we need this**\n",
    "* Right now, our data is in the form of PyTorch Datasets\n",
    "* Dataloader turns our dataset into a Python iterable\n",
    "* We want to turn our data into batches (mini-batches)\n",
    "* **`Documentation`**: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d1671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x21c8f577340>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x21c8f576d40>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# setup the batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# turn dataset into python iterable(batches)\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)           # its good/easy of test data is not shuffled\n",
    "train_dataloader, test_dataloader                     # instances of the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ee137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f60494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_dataloaders: 1875 batches of 32\n",
      "Length of test_dataloaders: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# checkout how many batches of 32 size has been formed\n",
    "print(f\"Length of train_dataloaders: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test_dataloaders: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02e5734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout the first batch of the dataloaders\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5727e",
   "metadata": {},
   "source": [
    "## Visualize the Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05edc9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: torch.Size([1, 28, 28])\n",
      "Label: 8, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "print(f\"Image Size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217ec10",
   "metadata": {},
   "source": [
    "## Build a baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53772d45",
   "metadata": {},
   "source": [
    "### understanding the concept of flatten layer\n",
    "* In baseline model we are going to use the linear layer, which can't handle thet multidimensional data, hence we are converting into single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c45f3978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape after flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "# create a flatten layer\n",
    "flatten_model = nn.Flatten()              # nn.Flatten() can be used as model\n",
    "\n",
    "# get sample from train data\n",
    "sample = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "flattened_sample = flatten_model(sample) # performing the forward pass\n",
    "\n",
    "# print out result\n",
    "print(f\"Shape before flattening: {sample.shape}\")\n",
    "print(f\"Shape after flattening: {flattened_sample.shape}\")  # [color channel, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf0063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNIST(\n",
       "  (layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "class FashionMNIST(nn.Module):\n",
    "    \"\"\"Initialize the FashionMNIST muti-class classification model\n",
    "    \n",
    "    Args:\n",
    "        input_features(int): Number of input features to the model\n",
    "        output_features(int): Number of output features by the model\n",
    "        hidden_units(int): Number of hidden units between the layers\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_features: int,\n",
    "                 output_features: int,\n",
    "                 hidden_units: int):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),      # in order to pass the data into linear layer\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features),\n",
    "            )\n",
    "    \n",
    "    # over-ride the forward method\n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        return self.layers(x) \n",
    "\n",
    "modelbase = FashionMNIST(input_features=784,        # 28x28\n",
    "                         output_features=10,        # ten output classes in datasets\n",
    "                         hidden_units=10).to(\"cpu\")   \n",
    "\n",
    "modelbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78645462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers.1.weight',\n",
       "              tensor([[-0.0042, -0.0145,  0.0237,  ..., -0.0319,  0.0206, -0.0111],\n",
       "                      [-0.0272,  0.0052,  0.0173,  ...,  0.0023,  0.0029,  0.0097],\n",
       "                      [ 0.0272, -0.0169,  0.0213,  ...,  0.0307, -0.0014, -0.0287],\n",
       "                      ...,\n",
       "                      [-0.0101, -0.0093,  0.0068,  ..., -0.0126, -0.0139, -0.0208],\n",
       "                      [-0.0275,  0.0082,  0.0330,  ...,  0.0330,  0.0033,  0.0030],\n",
       "                      [-0.0047, -0.0345,  0.0140,  ...,  0.0228,  0.0321, -0.0169]])),\n",
       "             ('layers.1.bias',\n",
       "              tensor([ 0.0152, -0.0084,  0.0227, -0.0054, -0.0284, -0.0354, -0.0013,  0.0105,\n",
       "                      -0.0211,  0.0281])),\n",
       "             ('layers.2.weight',\n",
       "              tensor([[ 0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565, -0.2877,\n",
       "                       -0.1792,  0.2305],\n",
       "                      [-0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,  0.1030,\n",
       "                       -0.2715, -0.1596],\n",
       "                      [-0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,  0.2252,\n",
       "                       -0.2160, -0.2725],\n",
       "                      [ 0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366, -0.1533,\n",
       "                        0.0965, -0.1184],\n",
       "                      [-0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307, -0.2629,\n",
       "                        0.0133,  0.2727],\n",
       "                      [-0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,  0.2488,\n",
       "                       -0.2571,  0.0425],\n",
       "                      [-0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,  0.1943,\n",
       "                        0.2853, -0.1310],\n",
       "                      [ 0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,  0.0012,\n",
       "                       -0.0810, -0.0087],\n",
       "                      [ 0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266, -0.2612,\n",
       "                       -0.2613, -0.2624],\n",
       "                      [ 0.1987, -0.1606,  0.1747, -0.0471, -0.1303,  0.2380, -0.0611, -0.1707,\n",
       "                       -0.0485, -0.2011]])),\n",
       "             ('layers.2.bias',\n",
       "              tensor([-0.3045, -0.0554, -0.0178, -0.1802,  0.2803, -0.0706, -0.0803,  0.2506,\n",
       "                       0.0352, -0.0744]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelbase.state_dict()     # checking the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82c7b3",
   "metadata": {},
   "source": [
    "### Downloading the python script from github using code\n",
    "* **import accuracy helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60deb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_funtions.py already exits, skipping download.....\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# downloade helper functions from gitub repo\n",
    "if Path(\"helper_funtions.py\").is_file():\n",
    "    print(\"helper_funtions.py already exits, skipping download.....\")\n",
    "else:\n",
    "    print(\"Downloading helper_funtions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_funtions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fb714b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_funtions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4276a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# setup an optimizer\n",
    "optimizer = torch.optim.SGD(params=modelbase.parameters(), \n",
    "                            lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14940ff",
   "metadata": {},
   "source": [
    "### Creating a function to time our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7113234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start:float,\n",
    "                     end:float,\n",
    "                     device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time\"\"\"\n",
    "    \n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device} : {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363012d",
   "metadata": {},
   "source": [
    "## Creating a training loop and training model on batches of data\n",
    "**Steps:**\n",
    "* Loop through batches\n",
    "* Loop through training batches, perform training steps, calculate train loss per batch.\n",
    "* Loop through testing batches, perform testing steps, calculate test loss per batch.\n",
    "* Print out the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47851ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f77eb8a884dc9bb705a67a9762174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4319 | Test Loss: 0.4790, Test acc 83.4764\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4319 | Test Loss: 0.4790, Test acc 83.4764\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4319 | Test Loss: 0.4790, Test acc 83.4764\n",
      "Train time on cpu : 28.477 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.477369099999123"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# set the seed and start time\n",
    "train_start_time_cpu = timer()\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# set the no of epochs\n",
    "epochs = 3\n",
    "\n",
    "# create a training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch+1}\\n-----\")\n",
    "    \n",
    "    ## start the training mode\n",
    "    train_loss = 0\n",
    "    \n",
    "    ## add loop to loop through the training batches\n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        ## set the model on training mode\n",
    "        modelbase.train()\n",
    "        \n",
    "        ## forward passs\n",
    "        y_pred = modelbase(X)\n",
    "        \n",
    "        ## calculate the loss(per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss               # accumulating the training loss\n",
    "        \n",
    "        ## zero-out the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## print out stats per batch\n",
    "        \n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "            \n",
    "    # Divide the total train_loss by length of train dataloader (no of batches)\n",
    "    train_loss = train_loss/ len(train_dataloader)         # average loss per epoch\n",
    "    \n",
    "    \n",
    "    ## Testing loop \n",
    "    test_loss, test_acc = 0,0\n",
    "    \n",
    "    # set the model on eval() mode\n",
    "    modelbase.eval()\n",
    "    \n",
    "    # turn on the inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop through images, labels in test_dataloader\n",
    "        for X_test,y_test in test_dataloader:\n",
    "            ## do the forward pass\n",
    "            test_pred = modelbase(X_test)\n",
    "            \n",
    "            ## calculate the testing loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            \n",
    "            ## calculate the accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "         ## calculate the test loss average per batch\n",
    "        test_loss = test_loss/ len(test_dataloader)\n",
    "        \n",
    "        ## calculate the test acc average per batch\n",
    "        test_acc = test_acc/ len(test_dataloader)\n",
    "    \n",
    "    ## print out the training and testing stats\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test acc {test_acc:.4f}\" )\n",
    "        \n",
    "                 \n",
    "train_time_end_cpu = timer()\n",
    "total_train_time_model_cpu= print_train_time(start=train_start_time_cpu, \n",
    "                       end=train_time_end_cpu, \n",
    "                       device=str(next(modelbase.parameters()).device))\n",
    "total_train_time_model_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306c871",
   "metadata": {},
   "source": [
    "## Make predication and  evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "049aa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.dataloader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\"\"\"\n",
    "    \n",
    "    loss, acc = 0, 0\n",
    "    #set the model on eval mode\n",
    "    model.eval()\n",
    "     \n",
    "    \n",
    "    # turn on the inference mode\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            # Make our data device agnostic\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # make predications-forward pass\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # accumulate the test loss and accuracy per batch\n",
    "            loss += loss_fn(y_pred,y)\n",
    "            acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
    "        \n",
    "        # Find the average loss\n",
    "        loss = loss/len(data_loader)\n",
    "        acc = acc/len(data_loader)\n",
    "    \n",
    "    return {\"model_name\": model.__class__.__name__, \n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6ae926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e271e0cf98f453ebc89648227cd877b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the modelbase results\n",
    "modelbase_results = eval_model(model=modelbase, \n",
    "                               data_loader=test_dataloader, \n",
    "                               loss_fn=loss_fn, \n",
    "                               accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "346fd78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNIST',\n",
       " 'model_loss': 0.47896072268486023,\n",
       " 'model_acc': 83.47643769968052}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelbase_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10733324",
   "metadata": {},
   "source": [
    "## Setup the device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe1fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  5 13:42:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.78       Driver Version: 512.78       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   46C    P8     4W /  N/A |    282MiB /  4096MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     14304    C+G   ...mmandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A     14744    C+G   ...ightStudio-background.exe    N/A      |\n",
      "|    0   N/A  N/A     18608    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "|    0   N/A  N/A     19412    C+G   ...6XXFWB44ZAJBOQQ\\DeepL.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fee9feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b026de",
   "metadata": {},
   "source": [
    "## Build a Model using non-linearities and on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39b101f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNISTV1(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "Model Device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "class FashionMNISTV1(nn.Module):\n",
    "    \"\"\"Initialize the model FashionMNISTV1 for multi-class classification\n",
    "    \n",
    "    Args:\n",
    "        input_features(int): Number of input features to the model\n",
    "        output_features(int): Number of output features given by the model\n",
    "        hidden_units(int): Number of hidden units between the layers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_shape:int, \n",
    "                 output_shape:int, \n",
    "                 hidden_units:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        ## define the model architecture\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=output_shape),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    ## over-ride the forward method\n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "# create an object of the model\n",
    "modelv1 = FashionMNISTV1(input_shape=28*28,                # 28*28\n",
    "                         output_shape=10,                  # 10 output classes\n",
    "                         hidden_units=10).to(device)       # send the model to target device i.e \"cuda\" if available\n",
    "print(modelv1)\n",
    "print(f\"\\nModel Device:{next(modelv1.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d05332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the loss function, optimizer\n",
    "from helper_funtions import accuracy_fn\n",
    "\n",
    "# loss funtion\n",
    "loss_fn = nn.CrossEntropyLoss()       # measure how wrong our model predication is w.r.t to target\n",
    "optimizer = torch.optim.SGD(params=modelv1.parameters(),  # optimise the model parameters using gradient method\n",
    "                            lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cc000c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for batch , (X,y) in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f6579",
   "metadata": {},
   "source": [
    "## Functionizing training and testing loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2789f",
   "metadata": {},
   "source": [
    "### Train_step():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b3718d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c7e5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training loop - train_step()\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.dataloader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"performs a training with model trying to learn on data_loaders\"\"\"\n",
    "    train_loss, train_acc = 0,0\n",
    "    \n",
    "    ## add a loop through the training batches of the train dataloaders\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        ## set the model on train mode\n",
    "        model.train()\n",
    "        \n",
    "        # put the data on the target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        ## make predications using forward passs\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        ## calculate the loss per batch\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_loss+= loss\n",
    "        train_acc += accuracy_fn(y_true=y, \n",
    "                                 y_pred = y_pred.argmax(dim=1)) # argmax converting the raw logits --> predication labels\n",
    "        \n",
    "        ## zero-out the optimizer gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## backpropagate the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        ## take optimisation step\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## print out how many samples we have pass through the optimization step\n",
    "        if batch%400 == 0:\n",
    "            print(f\"No of samples passed through gradient optimization {batch*len(X)}/{len(dataloader.dataset)} sample...\")   \n",
    "\n",
    "        ## calculate the average loss per epoch \n",
    "    train_loss /= len(dataloader) # divide by no of bacthes \n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2c7da",
   "metadata": {},
   "source": [
    "### Test_step():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f1f8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.dataloader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn = accuracy_fn,\n",
    "              device: torch.device= device):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # set the mode on eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on the inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop through dataloader\n",
    "        for X,y in dataloader:\n",
    "            # put the data on the target device\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            \n",
    "            # make predications --> do the forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # calculate the loss/acc\n",
    "            test_loss += loss_fn(test_pred,y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred = test_pred.argmax(dim=1)) # argmax to convert the raw logits into predication labels\n",
    "        \n",
    "        # adjust the loss and accuracy\n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.5f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325de4f",
   "metadata": {},
   "source": [
    "### Use train_step() and test_step() to write the final training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d250e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e51db8891e7480499396e156253b855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 1.11456 | Train acc: 58.46%\n",
      "Test Loss: 0.96320 | Test Acc: 63.40855%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 0.90905 | Train acc: 64.87%\n",
      "Test Loss: 0.74544 | Test Acc: 72.61382%\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 0.59506 | Train acc: 78.26%\n",
      "Test Loss: 0.49534 | Test Acc: 82.67772%\n",
      "\n",
      "Train time on cuda : 38.902 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "start_train_time_gpu = timer()\n",
    "\n",
    "# set the epochs\n",
    "epochs = 3\n",
    "\n",
    "# create a final training and testing loop using train_step() and test_step() function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch+1}\\n-------\")\n",
    "    \n",
    "    ## training step\n",
    "    train_step(model=modelv1, \n",
    "               dataloader=train_dataloader, \n",
    "               loss_fn=nn.CrossEntropyLoss(), \n",
    "               optimizer=optimizer, \n",
    "               accuracy_fn=accuracy_fn, \n",
    "               device=device)\n",
    "    \n",
    "    ## test step\n",
    "    test_step(model=modelv1, \n",
    "              dataloader=test_dataloader,\n",
    "              loss_fn=nn.CrossEntropyLoss(),\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "end_train_time_gpu = timer()\n",
    "total_train_time_gpu = print_train_time(start=start_train_time_gpu,\n",
    "                                        end=end_train_time_gpu, \n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9b199",
   "metadata": {},
   "source": [
    "### Why my GPU compute time is slower than CPU compute time\n",
    "**Reasons: Why is this ? **\n",
    "1. It could be that overhead for copying the data/model to and from the GPU outweights the compute benefits offered by the GPU.\n",
    "2. Hardware has a better cpu in terms of compute capability than the GPU\n",
    "\n",
    "**`Article to know more about GPU computing:`**: https://horace.io/brrr_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ff210a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c95cb39fd64364b62dbeba023b2ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTV1',\n",
       " 'model_loss': 0.495336651802063,\n",
       " 'model_acc': 82.67771565495208}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv1_results = eval_model(model=modelv1,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "modelv1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f66d1d",
   "metadata": {},
   "source": [
    "## Building a Convolutional Neural Network Model\n",
    "\n",
    "**`Good Resource`**: https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6522d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cnn model\n",
    "\n",
    "class FashionMNISTV2(nn.Module):\n",
    "    \"\"\"Model architecture that replicates the TinyVGG model from CNN explainer website\"\"\"\n",
    "    def __init__(self, input_shape:int, output_shape:int, hidden_units:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # understood as feature extraction block 1\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units, kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # understood as feature extraction block 2\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # understood as classifier layer\n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Flatten(),                         # to flatten out the 2x2 matrix from previous layer into vector\n",
    "            nn.Linear(in_features=hidden_units*7*7, # there is trick to calculate this\n",
    "                      out_features=output_shape), \n",
    "        )\n",
    "        \n",
    "    def forward(self,x:torch.Tensor)-> torch.Tensor:\n",
    "        x = self.conv_block1(x);\n",
    "#         print(x.shape)\n",
    "        x = self.conv_block2(x);\n",
    "#         print(x.shape)\n",
    "        x = self.classfier(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0afd694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTV2(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classfier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "modelv2 = FashionMNISTV2(input_shape=1,       # input color channels\n",
    "                         output_shape=10,     # output classes\n",
    "                         hidden_units=10).to(device)\n",
    "modelv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39e658",
   "metadata": {},
   "source": [
    "### understanding working of conv2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbedbd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dummy_image_batch = torch.rand(size=(32,1,28,28))\n",
    "dummy_image = dummy_image_batch[0]\n",
    "\n",
    "print(dummy_image_batch.shape)\n",
    "print(dummy_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04e53349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 26, 26])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_2d_dummy = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3,3),stride=1, padding=0)\n",
    "# do the forward pass through conv2d\n",
    "result = conv_2d_dummy(dummy_image) # with unsqueeze output size is : torch.Size([1, 10, 62, 62])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653be67",
   "metadata": {},
   "source": [
    "### understanding of max2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b128c6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_image.shape # printout shape of original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a156945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "# create dummy_max2dpool layer\n",
    "max2d_dummy = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# do forward pass\n",
    "maxpool_output = max2d_dummy(dummy_image)\n",
    "print(maxpool_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60944ad5",
   "metadata": {},
   "source": [
    "### Here's the trick to understand how to calculate the output_features shape in the final classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11cc3711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLook at the error and the shapes that we have printed after each forward layer through conv block\\n---\\ntorch.Size([1, 10, 62, 62])\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv2(dummy_image.unsqueeze(0).to(device))\n",
    "\n",
    "\"\"\"\n",
    "Look at the error and the shapes that we have printed after each forward layer through conv block\n",
    "---\n",
    "torch.Size([1, 10, 62, 62])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85299ac",
   "metadata": {},
   "source": [
    "## Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5dc50c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=modelv2.parameters(),\n",
    "                            lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f4882b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ef3234a4224710aaf9018417046338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 1.03787 | Train acc: 62.34%\n",
      "Test Loss: 0.62510 | Test Acc: 76.86701%\n",
      "\n",
      "Epoch: 1\n",
      "----\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 0.54918 | Train acc: 80.01%\n",
      "Test Loss: 0.49867 | Test Acc: 81.53954%\n",
      "\n",
      "Epoch: 2\n",
      "----\n",
      "No of samples passed through gradient optimization 0/60000 sample...\n",
      "No of samples passed through gradient optimization 12800/60000 sample...\n",
      "No of samples passed through gradient optimization 25600/60000 sample...\n",
      "No of samples passed through gradient optimization 38400/60000 sample...\n",
      "No of samples passed through gradient optimization 51200/60000 sample...\n",
      "Train Loss: 0.45581 | Train acc: 83.53%\n",
      "Test Loss: 0.44001 | Test Acc: 84.27516%\n",
      "\n",
      "Train time on cuda : 107.444 seconds\n"
     ]
    }
   ],
   "source": [
    "## setup the training and testing loop using train_step() and test_step() functions\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "## Measure time\n",
    "from timeit import default_timer as timer\n",
    "start_train_time_modelv2 = timer()\n",
    "\n",
    "## Train and Test loop\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n----\")\n",
    "    train_step(model=modelv2,\n",
    "               dataloader=train_dataloader,\n",
    "               loss_fn=loss_fn, \n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn, \n",
    "               device=device)\n",
    "    \n",
    "    test_step(model=modelv2, \n",
    "              dataloader=test_dataloader, \n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "end_train_time_modelv2 = timer()\n",
    "total_train_time_modelv2_gpu = print_train_time(start=start_train_time_modelv2, \n",
    "                                                end=end_train_time_modelv2, \n",
    "                                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "61bdafb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a994728d68b94442892620ab0225d4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modelv2 results\n",
    "modelv2_results = eval_model(model=modelv2,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51a074e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTV2',\n",
       " 'model_loss': 0.4400119483470917,\n",
       " 'model_acc': 84.27515974440895}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871657e8",
   "metadata": {},
   "source": [
    "## Compare the different models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce9991e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>0.478961</td>\n",
       "      <td>83.476438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTV1</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>82.677716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTV2</td>\n",
       "      <td>0.440012</td>\n",
       "      <td>84.275160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name  model_loss  model_acc\n",
       "0    FashionMNIST    0.478961  83.476438\n",
       "1  FashionMNISTV1    0.495337  82.677716\n",
       "2  FashionMNISTV2    0.440012  84.275160"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_model_results = pd.DataFrame([modelbase_results, modelv1_results, modelv2_results])\n",
    "compare_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c8050e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add training time to dataframes\n",
    "compare_model_results[\"training_time\"] = [total_train_time_model_cpu, total_train_time_gpu, total_train_time_modelv2_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "478f47e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNIST</td>\n",
       "      <td>0.478961</td>\n",
       "      <td>83.476438</td>\n",
       "      <td>28.477369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTV1</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>82.677716</td>\n",
       "      <td>38.901632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTV2</td>\n",
       "      <td>0.440012</td>\n",
       "      <td>84.275160</td>\n",
       "      <td>107.443841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name  model_loss  model_acc  training_time\n",
       "0    FashionMNIST    0.478961  83.476438      28.477369\n",
       "1  FashionMNISTV1    0.495337  82.677716      38.901632\n",
       "2  FashionMNISTV2    0.440012  84.275160     107.443841"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbdbb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
